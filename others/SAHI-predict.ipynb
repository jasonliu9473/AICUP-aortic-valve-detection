{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b783c012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sahi import AutoDetectionModel\n",
    "from sahi.predict import get_sliced_prediction\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "FOLD_NUM = 7\n",
    "\n",
    "for idx in range(FOLD_NUM):\n",
    "    # Load model using SAHI's AutoDetectionModel\n",
    "    model_path = f\"/mnt/data/aorta/yolo12x_fold7_best/yolo12x_fold7_1_{idx}/weights/best.pt\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Loading Model {idx}...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    detection_model = AutoDetectionModel.from_pretrained(\n",
    "        model_type='ultralytics',\n",
    "        model_path=model_path,\n",
    "        confidence_threshold=0.1,\n",
    "        device=\"cuda:0\"\n",
    "    )\n",
    "    \n",
    "    # Get all images in the directory\n",
    "    source_dir = \"./aorta_detection/datasets/all_test/\"\n",
    "    image_paths = list(Path(source_dir).glob(\"*.png\"))\n",
    "    image_paths = sorted(image_paths)\n",
    "    \n",
    "    total_images = len(image_paths)\n",
    "    print(f\"Found {total_images} images to process\")\n",
    "    \n",
    "    # Open output file\n",
    "    output_file = open(\n",
    "        f'./kfold_predict_txt/positive/best_model{idx}_conf1e-5_sahi.txt', \n",
    "        'w'\n",
    "    )\n",
    "    \n",
    "    # Track timing\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Process each image with progress bar\n",
    "    for img_idx, img_path in enumerate(tqdm(image_paths, desc=f\"Model {idx}\", unit=\"img\")):\n",
    "        img_start = time.time()\n",
    "        \n",
    "        # Perform sliced inference with SAHI\n",
    "        result = get_sliced_prediction(\n",
    "            str(img_path),\n",
    "            detection_model,\n",
    "            slice_height=180,\n",
    "            slice_width=180,\n",
    "            overlap_height_ratio=0.2,\n",
    "            overlap_width_ratio=0.2,\n",
    "            postprocess_match_metric=\"IOS\",\n",
    "            postprocess_match_threshold=0.75,\n",
    "            postprocess_class_agnostic=False\n",
    "        )\n",
    "        \n",
    "        # Get filename without extension\n",
    "        filename = img_path.stem\n",
    "        \n",
    "        # Extract predictions from SAHI result\n",
    "        det_count = 0\n",
    "        for obj_pred in result.object_prediction_list:\n",
    "            bbox = obj_pred.bbox\n",
    "            x1, y1, x2, y2 = bbox.minx, bbox.miny, bbox.maxx, bbox.maxy\n",
    "            label = obj_pred.category.id\n",
    "            conf = obj_pred.score.value\n",
    "            \n",
    "            line = f\"{filename} {label} {conf:.4f} {int(x1)} {int(y1)} {int(x2)} {int(y2)}\\n\"\n",
    "            output_file.write(line)\n",
    "            det_count += 1\n",
    "        \n",
    "        img_time = time.time() - img_start\n",
    "        \n",
    "        # Print detailed progress every 10 images\n",
    "        if (img_idx + 1) % 10 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            avg_time = elapsed / (img_idx + 1)\n",
    "            remaining = avg_time * (total_images - img_idx - 1)\n",
    "            print(f\"\\n  Progress: {img_idx + 1}/{total_images} | \"\n",
    "                  f\"Detections: {det_count} | \"\n",
    "                  f\"Time: {img_time:.2f}s | \"\n",
    "                  f\"ETA: {remaining/60:.1f}m\")\n",
    "    \n",
    "    # Close output file\n",
    "    output_file.close()\n",
    "    \n",
    "    # Print summary\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Model {idx} Complete!\")\n",
    "    print(f\"Total time: {total_time/60:.2f} minutes\")\n",
    "    print(f\"Average time per image: {total_time/total_images:.2f}s\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Clean up memory\n",
    "    del detection_model, result\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\nâœ“ All models processed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db03496a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b70808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab5f55d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aorta venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
